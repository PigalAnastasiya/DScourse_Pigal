{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое задание: Разработка и оценка рекомендательных систем\n",
    "\n",
    "Цель:\n",
    "Разработать различные модели рекомендательных систем и оценить их качество с использованием разных метрик.\n",
    "\n",
    "Данные:\n",
    "The Movies Dataset от GroupLens.\n",
    "\n",
    "Шаги:\n",
    "\n",
    "Подготовка данных\n",
    "\n",
    "Загрузите датасет.\n",
    "Подготовьте данные: создайте матрицу пользователь-фильм на основе рейтингов.\n",
    "Разработка рекомендательных систем\n",
    "\n",
    "Content-based рекомендация: Используйте жанры, ключевые слова и другие характеристики фильма для рекомендации.\n",
    "Collaborative Filtering:\n",
    "User-based: Используйте схожесть между пользователями.\n",
    "Item-based: Используйте схожесть между элементами (фильмами).\n",
    "Matrix Factorization: Используйте SVD.\n",
    "Оценка качества рекомендательных систем\n",
    "\n",
    "Разделите данные на обучающую и тестовую выборки.\n",
    "Используйте следующие метрики для оценки качества каждой модели:\n",
    "RMSE (Root Mean Squared Error): Используйте для моделей, которые предсказывают рейтинг.\n",
    "Precision@k и Recall@k: Оцените, сколько рекомендованных элементов действительно интересны пользователю.\n",
    "Hit Rate: Как часто рекомендация совпадает с предпочтением пользователя.\n",
    "Diversity: Измеряет насколько разнообразными являются рекомендации.\n",
    "Выводы\n",
    "\n",
    "Какая модель показала себя лучше всего по каждой метрике?\n",
    "Какие сложности и ограничения вы столкнулись при разработке и оценке моделей?\n",
    "Какие улучшения можно внести в текущие модели?\n",
    "Дополнительные задачи (для продвинутых пользователей):\n",
    "- Попробуйте использовать гибридные системы, комбинируя различные методы.\n",
    "- Исследуйте возможность использования deep learning для создания рекомендаций.\n",
    "- Исследуйте, как cold start problem (проблема нового пользователя или нового элемента) влияет на каждую из моделей и как с этим можно бороться.\n",
    "\n",
    "После выполнения этого задания вы получите представление о различных подходах к созданию рекомендательных систем и научитесь оценивать их качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import ast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "data = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
    "data = data.dropna(subset='overview')\n",
    "descriptions = data['overview']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genres(genres_str):\n",
    "    genres_list=ast.literal_eval(genres_str)\n",
    "    genres_cleaned = \" \".join([g[\"name\"]for g in genres_list])\n",
    "    return genres_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['genres_cleaned'] = data['genres'].apply(extract_genres)\n",
    "genres_description = data[\"genres_cleaned\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация метода на основе контента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Векторизация описаний и жанров\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=10000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(descriptions)\n",
    "tfidf_matrix_genres = tfidf_vectorizer.fit_transform(genres_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "combined_matrix = hstack([tfidf_matrix,tfidf_matrix_genres])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Вычисление косинусного сходства\n",
    "cosine_sim= linear_kernel(combined_matrix, combined_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Функция для получения рекомендаций\n",
    "def get_recommendations(title, n=10):\n",
    "    idx = data.index[data['title'] == title].tolist()[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:n+1]  # Возвращаем n наиболее похожих фильмов\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return data['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31746                      That Night\n",
      "9094                        The Boxer\n",
      "6204                         The Trip\n",
      "44075                        The Nude\n",
      "37017                             Boy\n",
      "40208             Morris from America\n",
      "196        The Umbrellas of Cherbourg\n",
      "18177                    Lebanon, Pa.\n",
      "9209     Water Drops on Burning Rocks\n",
      "12333                  Rachel, Rachel\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 5. Тестирование системы\n",
    "print(get_recommendations('The Matrix'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Вычисление Евклидово расстояния\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "euclidean_sim= euclidean_distances(combined_matrix, combined_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-based подход"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка данных\n",
    "movies = pd.read_csv('movies_metadata.csv', low_memory=False)\n",
    "ratings = pd.read_csv('ratings_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = ratings['userId'].unique().shape[0]\n",
    "n_items = ratings['movieId'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.drop(['timestamp'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем матрицу предпочтений\n",
    "user_item_matrix =ratings.pivot(index='userId', columns = 'movieId', values = 'rating')\n",
    "user_item_matrix.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делим данные на тренировочный и тестовый наборы\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data,test_data= train_test_split(user_item_matrix,test_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "user_similarity = pairwise_distances(train_data, metric='cosine')\n",
    "item_similarity = pairwise_distances(train_data.T, metric='cosine')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m pred\n\u001b[0;32m      9\u001b[0m item_prediction \u001b[39m=\u001b[39m predict(train_data, item_similarity, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m user_prediction \u001b[39m=\u001b[39m predict(train_data, user_similarity, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[126], line 4\u001b[0m, in \u001b[0;36mpredict\u001b[1;34m(ratings, similarity, type)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m      3\u001b[0m     mean_user_rating \u001b[39m=\u001b[39m ratings\u001b[39m.\u001b[39mmean(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     ratings_diff \u001b[39m=\u001b[39m (ratings \u001b[39m-\u001b[39m mean_user_rating[:, np\u001b[39m.\u001b[39;49mnewaxis])\n\u001b[0;32m      5\u001b[0m     pred \u001b[39m=\u001b[39m mean_user_rating[:, np\u001b[39m.\u001b[39mnewaxis] \u001b[39m+\u001b[39m similarity\u001b[39m.\u001b[39mdot(ratings_diff) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39marray([np\u001b[39m.\u001b[39mabs(similarity)\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)])\u001b[39m.\u001b[39mT\n\u001b[0;32m      6\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mtype\u001b[39m \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mitem\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1033\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1030\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m   1031\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[1;32m-> 1033\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1048\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1043\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   1044\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIndexing a Series with DataFrame is not \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1045\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported, use the appropriate DataFrame column\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1046\u001b[0m     )\n\u001b[0;32m   1047\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m-> 1048\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_values_tuple(key)\n\u001b[0;32m   1050\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key):\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# e.g. scalars that aren't recognized by lib.is_scalar, GH#32684\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloc[key]\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:1082\u001b[0m, in \u001b[0;36mSeries._get_values_tuple\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1077\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39many_none(\u001b[39m*\u001b[39mkey):\n\u001b[0;32m   1078\u001b[0m     \u001b[39m# mpl compat if we look up e.g. ser[:, np.newaxis];\u001b[39;00m\n\u001b[0;32m   1079\u001b[0m     \u001b[39m#  see tests.series.timeseries.test_mpl_compat_hack\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[39m# the asarray is needed to avoid returning a 2D DatetimeArray\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key])\n\u001b[1;32m-> 1082\u001b[0m     disallow_ndim_indexing(result)\n\u001b[0;32m   1083\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, MultiIndex):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexers\\utils.py:343\u001b[0m, in \u001b[0;36mdisallow_ndim_indexing\u001b[1;34m(result)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[39mHelper function to disallow multi-dimensional indexing on 1D Series/Index.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[39min GH#30588.\u001b[39;00m\n\u001b[0;32m    341\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(result) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    344\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMulti-dimensional indexing (e.g. `obj[:, None]`) is no longer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    345\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupported. Convert to a numpy array before indexing instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    346\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Multi-dimensional indexing (e.g. `obj[:, None]`) is no longer supported. Convert to a numpy array before indexing instead."
     ]
    }
   ],
   "source": [
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred\n",
    "item_prediction = predict(train_data, item_similarity, type='item')\n",
    "user_prediction = predict(train_data, user_similarity, type='user')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "print ('User based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print ('Item based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
